# ğŸ” RAG with Groq + LangChain + ChromaDB

This project implements a **Retrieval-Augmented Generation (RAG)** pipeline using:

- ğŸ’¬ [Groq](https://groq.com/) â€” fast inference with LLaMA or Gemma
- ğŸ§  LangChain â€” document parsing, chunking, and chaining
- ğŸ“„ Local PDFs â€” user-loaded documents
- ğŸ§· ChromaDB â€” local vector store for embeddings

---

## ğŸ“ Folder Structure

vector_db/ <br>
â”œâ”€â”€ notebook.ipynb # Main Jupyter notebook with code <br>
â”œâ”€â”€ docs/ # Your local PDFs <br>
â”œâ”€â”€ vector_store/ # Chroma vector storage (auto-generated) <br>
â”œâ”€â”€ .env # API key (not included in repo) <br>
â”œâ”€â”€ .gitignore <br>
â”œâ”€â”€ requirements.txt <br>
â””â”€â”€ README.md


---

## ğŸš€ How to Run

1. **Clone the repo**

```git clone https://github.com/your-username/vector_db.git```<br>
```cd vector_db ```

3. **Install dependencies**

```pip install -r requirements.txt```

3. **Add your Groq API key**

Create a .env file with:

```GROQ_API_KEY=your_api_key_here```

4. **Add your PDFs to the docs/ folder.**

Open the notebook
Run `notebook.ipynb` in Jupyter and follow the steps.
